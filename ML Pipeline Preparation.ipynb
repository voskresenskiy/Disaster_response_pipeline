{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql_table('disaster_response', engine)  \n",
    "X = df.iloc[:,0:4]\n",
    "Y = df.iloc[:,5:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.lower() not in stopwords.words(\"english\")]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.drop('child_alone', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train['message'], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = list(Y.columns)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93      5423\n",
      "          1       0.80      0.44      0.57      1157\n",
      "\n",
      "avg / total       0.88      0.88      0.87      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6553\n",
      "          1       1.00      0.04      0.07        27\n",
      "\n",
      "avg / total       1.00      1.00      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.86      0.79      3841\n",
      "          1       0.74      0.57      0.64      2739\n",
      "\n",
      "avg / total       0.74      0.74      0.73      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.96      6037\n",
      "          1       0.60      0.09      0.16       543\n",
      "\n",
      "avg / total       0.90      0.92      0.89      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6229\n",
      "          1       0.77      0.07      0.13       351\n",
      "\n",
      "avg / total       0.94      0.95      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      6404\n",
      "          1       0.48      0.06      0.11       176\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6451\n",
      "          1       0.50      0.01      0.02       129\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6355\n",
      "          1       0.57      0.08      0.13       225\n",
      "\n",
      "avg / total       0.95      0.97      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6580\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6139\n",
      "          1       0.90      0.24      0.37       441\n",
      "\n",
      "avg / total       0.94      0.95      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      5854\n",
      "          1       0.82      0.44      0.57       726\n",
      "\n",
      "avg / total       0.92      0.93      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      5988\n",
      "          1       0.79      0.26      0.39       592\n",
      "\n",
      "avg / total       0.92      0.93      0.91      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6480\n",
      "          1       0.68      0.15      0.25       100\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6421\n",
      "          1       1.00      0.02      0.04       159\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6498\n",
      "          1       1.00      0.01      0.02        82\n",
      "\n",
      "avg / total       0.99      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6366\n",
      "          1       0.52      0.05      0.09       214\n",
      "\n",
      "avg / total       0.95      0.97      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6306\n",
      "          1       0.79      0.17      0.28       274\n",
      "\n",
      "avg / total       0.96      0.96      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93      5707\n",
      "          1       0.70      0.05      0.09       873\n",
      "\n",
      "avg / total       0.85      0.87      0.82      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6171\n",
      "          1       0.29      0.00      0.01       409\n",
      "\n",
      "avg / total       0.90      0.94      0.91      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6295\n",
      "          1       0.57      0.08      0.14       285\n",
      "\n",
      "avg / total       0.94      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6249\n",
      "          1       0.80      0.16      0.26       331\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6452\n",
      "          1       0.80      0.03      0.06       128\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6545\n",
      "          1       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6511\n",
      "          1       1.00      0.03      0.06        69\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6556\n",
      "          1       0.00      0.00      0.00        24\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6504\n",
      "          1       0.00      0.00      0.00        76\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6300\n",
      "          1       0.00      0.00      0.00       280\n",
      "\n",
      "avg / total       0.92      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.90      4758\n",
      "          1       0.82      0.60      0.69      1822\n",
      "\n",
      "avg / total       0.85      0.85      0.84      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      6055\n",
      "          1       0.86      0.37      0.52       525\n",
      "\n",
      "avg / total       0.94      0.94      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96      5949\n",
      "          1       0.74      0.41      0.53       631\n",
      "\n",
      "avg / total       0.92      0.93      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6512\n",
      "          1       1.00      0.03      0.06        68\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      5972\n",
      "          1       0.88      0.67      0.76       608\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6446\n",
      "          1       0.78      0.19      0.30       134\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6233\n",
      "          1       0.50      0.04      0.08       347\n",
      "\n",
      "avg / total       0.93      0.95      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91      5262\n",
      "          1       0.78      0.31      0.45      1318\n",
      "\n",
      "avg / total       0.84      0.84      0.82      6580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in category_names:\n",
    "    print(classification_report(y_test[i], y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__estimator__n_estimators': [50, 100, 200],\n",
    "    'clf__estimator__min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, param_grid=parameters, verbose = 5, n_jobs = -1, cv=2, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, score=0.7934432096983246, total= 3.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  4.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, score=0.7955468482257044, total= 3.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  9.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, score=0.8034745827085664, total= 5.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed: 15.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, score=0.8045407579060148, total= 5.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed: 22.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200, score=0.8077783518234741, total= 9.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200, score=0.8125869734825578, total= 9.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, score=0.795871942925752, total= 3.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, score=0.7986815631676302, total= 3.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, score=0.8081066333276922, total= 5.1min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, score=0.8082096382584517, total= 5.1min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200, score=0.8127099937389812, total= 8.5min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200, score=0.8164218079383837, total= 8.5min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, score=0.7993562816836846, total= 3.2min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, score=0.803317262746898, total= 3.2min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, score=0.8077110288309709, total= 4.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, score=0.8098239794466616, total= 4.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=200, score=0.8144858164286511, total= 8.0min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=200, score=0.8142000277119759, total= 8.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed: 124.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.814566 using {'clf__estimator__min_samples_split': 3, 'clf__estimator__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train['message'], y_train)\n",
    "print(\"Best: %f using %s\" % (model.best_score_, model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94      5492\n",
      "          1       0.84      0.51      0.63      1088\n",
      "\n",
      "avg / total       0.90      0.90      0.89      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6549\n",
      "          1       1.00      0.03      0.06        31\n",
      "\n",
      "avg / total       1.00      1.00      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.85      0.82      3861\n",
      "          1       0.76      0.68      0.72      2719\n",
      "\n",
      "avg / total       0.78      0.78      0.78      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      6042\n",
      "          1       0.80      0.07      0.13       538\n",
      "\n",
      "avg / total       0.91      0.92      0.89      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      6236\n",
      "          1       0.81      0.10      0.18       344\n",
      "\n",
      "avg / total       0.95      0.95      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6413\n",
      "          1       0.71      0.09      0.16       167\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6467\n",
      "          1       0.50      0.01      0.02       113\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6378\n",
      "          1       0.53      0.04      0.08       202\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6580\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6158\n",
      "          1       0.87      0.36      0.51       422\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97      5835\n",
      "          1       0.83      0.59      0.69       745\n",
      "\n",
      "avg / total       0.94      0.94      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      6010\n",
      "          1       0.78      0.39      0.52       570\n",
      "\n",
      "avg / total       0.93      0.94      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6468\n",
      "          1       0.90      0.08      0.15       112\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6419\n",
      "          1       0.83      0.03      0.06       161\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6517\n",
      "          1       0.00      0.00      0.00        63\n",
      "\n",
      "avg / total       0.98      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6385\n",
      "          1       0.50      0.02      0.03       195\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6290\n",
      "          1       0.78      0.12      0.21       290\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93      5724\n",
      "          1       0.67      0.03      0.05       856\n",
      "\n",
      "avg / total       0.85      0.87      0.82      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96      6119\n",
      "          1       0.20      0.00      0.00       461\n",
      "\n",
      "avg / total       0.88      0.93      0.90      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6276\n",
      "          1       0.85      0.12      0.20       304\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6204\n",
      "          1       0.82      0.12      0.21       376\n",
      "\n",
      "avg / total       0.94      0.95      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6454\n",
      "          1       0.83      0.04      0.08       126\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6543\n",
      "          1       0.00      0.00      0.00        37\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6497\n",
      "          1       0.00      0.00      0.00        83\n",
      "\n",
      "avg / total       0.97      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6552\n",
      "          1       0.00      0.00      0.00        28\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6503\n",
      "          1       0.00      0.00      0.00        77\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      6274\n",
      "          1       0.00      0.00      0.00       306\n",
      "\n",
      "avg / total       0.91      0.95      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92      4742\n",
      "          1       0.85      0.69      0.76      1838\n",
      "\n",
      "avg / total       0.88      0.88      0.88      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6052\n",
      "          1       0.91      0.49      0.64       528\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      5985\n",
      "          1       0.77      0.51      0.62       595\n",
      "\n",
      "avg / total       0.94      0.94      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6503\n",
      "          1       0.50      0.01      0.03        77\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      5966\n",
      "          1       0.89      0.79      0.84       614\n",
      "\n",
      "avg / total       0.97      0.97      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6447\n",
      "          1       0.83      0.08      0.14       133\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6236\n",
      "          1       0.58      0.02      0.04       344\n",
      "\n",
      "avg / total       0.93      0.95      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92      5301\n",
      "          1       0.82      0.37      0.51      1279\n",
      "\n",
      "avg / total       0.86      0.86      0.84      6580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,35):\n",
    "    print(classification_report(y_test.iloc[:,i], y_pred[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding genre as a feature\n",
    "\n",
    "In this part of the code, I am combining TfIdf vectorization with the binary variable representing the genre of the message. I am not planning to employ this model in the final version of the application as it does not assume to have a genre as an input. This coding part is rather done for the self-education and experimenting with pipelines.\n",
    "\n",
    "The following code is based on the following articles:\n",
    "\n",
    "https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65\n",
    "\n",
    "https://stackoverflow.com/questions/50523930/custom-transformers-and-gridsearch-valueerror-in-pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    \"\"\"class allows me to choose a variable for further transformations\"\"\"\n",
    "    def __init__( self, feature_names ):\n",
    "        self.feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self.feature_names ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelBinarizerPipelineFriendly(LabelBinarizer):\n",
    "    \"\"\"class allows me to fit the model based on the X input.\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        super(LabelBinarizerPipelineFriendly, self).fit(X)\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return super(LabelBinarizerPipelineFriendly, self).transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return super(LabelBinarizerPipelineFriendly, self).fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the pipeline binarizing the variable 'genre' and the pipeline vectorizing messages\n",
    "\n",
    "binarizer_pipeline = Pipeline( steps = [ ('first_selector', FeatureSelector('genre')),\n",
    "                                         ('binarizer', LabelBinarizerPipelineFriendly()) ])\n",
    "       \n",
    "tfidf_pipeline = Pipeline( steps = [ ('second_selector', FeatureSelector('message')),\n",
    "                                     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                                     ('tfidf', TfidfTransformer()) ])\n",
    "\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ('binarizer_pipeline', binarizer_pipeline ), \n",
    "                                                   ('tfidf_pipeline', tfidf_pipeline ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, applying Logistic regression to the transformed data\n",
    "full_pipeline_m = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                      ( 'clf', MultiOutputClassifier(LogisticRegression(random_state=2, \n",
    "                                                                                        solver='liblinear'))) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'clf__estimator__C': [0.001,0.01,0.1,1,10,100]}\n",
    "model = GridSearchCV(full_pipeline_m, params, n_jobs=-1, cv=2, verbose = 5, scoring ='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('full_pipeline', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('binarizer_pipeline', Pipeline(memory=None,\n",
       "     steps=[('first_selector', FeatureSelector(feature_names='genre')), ('binarizer', LabelBinarizerPipelineFriendly(neg_label=0, pos_label=1, sparse_output=False))])), ('tfidf_pipel...te=2, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline_m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV] clf__estimator__C=0.001 .........................................\n",
      "[CV]  clf__estimator__C=0.001, score=0.5782246716355237, total= 1.6min\n",
      "[CV] clf__estimator__C=0.001 .........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=0.001, score=0.5683026728722013, total= 1.6min\n",
      "[CV] clf__estimator__C=0.01 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . clf__estimator__C=0.01, score=0.7160395285578586, total= 1.6min\n",
      "[CV] clf__estimator__C=0.01 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . clf__estimator__C=0.01, score=0.7068898474359514, total= 1.6min\n",
      "[CV] clf__estimator__C=0.1 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  9.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. clf__estimator__C=0.1, score=0.7915739258430287, total= 1.6min\n",
      "[CV] clf__estimator__C=0.1 ...........................................\n",
      "[CV] .. clf__estimator__C=0.1, score=0.7946223855935297, total= 1.6min\n",
      "[CV] clf__estimator__C=1 .............................................\n",
      "[CV] .... clf__estimator__C=1, score=0.8364084738409863, total= 1.7min\n",
      "[CV] clf__estimator__C=1 .............................................\n",
      "[CV] .... clf__estimator__C=1, score=0.8404952130397332, total= 1.6min\n",
      "[CV] clf__estimator__C=10 ............................................\n",
      "[CV] ... clf__estimator__C=10, score=0.8318678024690688, total= 1.7min\n",
      "[CV] clf__estimator__C=10 ............................................\n",
      "[CV] ... clf__estimator__C=10, score=0.8323638963249798, total= 1.7min\n",
      "[CV] clf__estimator__C=100 ...........................................\n",
      "[CV] .. clf__estimator__C=100, score=0.8148278899603496, total= 1.7min\n",
      "[CV] clf__estimator__C=100 ...........................................\n",
      "[CV] .. clf__estimator__C=100, score=0.8148920308182076, total= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 29.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.838452 using {'clf__estimator__C': 1}\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (model.best_score_, model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94      5410\n",
      "          1       0.81      0.57      0.67      1170\n",
      "\n",
      "avg / total       0.90      0.90      0.89      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6551\n",
      "          1       0.00      0.00      0.00        29\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.86      0.82      3844\n",
      "          1       0.77      0.69      0.73      2736\n",
      "\n",
      "avg / total       0.79      0.79      0.78      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      6054\n",
      "          1       0.71      0.19      0.30       526\n",
      "\n",
      "avg / total       0.92      0.93      0.91      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6243\n",
      "          1       0.72      0.21      0.32       337\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6424\n",
      "          1       0.91      0.06      0.12       156\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6458\n",
      "          1       0.00      0.00      0.00       122\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6376\n",
      "          1       0.58      0.11      0.18       204\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      6151\n",
      "          1       0.79      0.55      0.65       429\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97      5832\n",
      "          1       0.84      0.63      0.72       748\n",
      "\n",
      "avg / total       0.94      0.94      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97      5970\n",
      "          1       0.78      0.43      0.56       610\n",
      "\n",
      "avg / total       0.93      0.94      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6470\n",
      "          1       0.74      0.23      0.35       110\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6425\n",
      "          1       0.67      0.08      0.14       155\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6511\n",
      "          1       0.00      0.00      0.00        69\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6357\n",
      "          1       0.76      0.07      0.13       223\n",
      "\n",
      "avg / total       0.96      0.97      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6287\n",
      "          1       0.85      0.24      0.37       293\n",
      "\n",
      "avg / total       0.96      0.96      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93      5726\n",
      "          1       0.57      0.11      0.19       854\n",
      "\n",
      "avg / total       0.84      0.87      0.84      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6153\n",
      "          1       0.33      0.02      0.03       427\n",
      "\n",
      "avg / total       0.90      0.93      0.91      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6262\n",
      "          1       0.80      0.12      0.21       318\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6254\n",
      "          1       0.79      0.24      0.36       326\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6440\n",
      "          1       0.71      0.11      0.19       140\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6538\n",
      "          1       0.00      0.00      0.00        42\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6516\n",
      "          1       0.00      0.00      0.00        64\n",
      "\n",
      "avg / total       0.98      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6553\n",
      "          1       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6491\n",
      "          1       0.00      0.00      0.00        89\n",
      "\n",
      "avg / total       0.97      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6293\n",
      "          1       0.33      0.01      0.01       287\n",
      "\n",
      "avg / total       0.93      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91      4741\n",
      "          1       0.84      0.66      0.74      1839\n",
      "\n",
      "avg / total       0.87      0.87      0.86      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6041\n",
      "          1       0.90      0.40      0.55       539\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96      5945\n",
      "          1       0.76      0.47      0.58       635\n",
      "\n",
      "avg / total       0.93      0.93      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6517\n",
      "          1       1.00      0.03      0.06        63\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98      5955\n",
      "          1       0.90      0.65      0.75       625\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6443\n",
      "          1       0.92      0.09      0.16       137\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6220\n",
      "          1       0.63      0.03      0.06       360\n",
      "\n",
      "avg / total       0.93      0.95      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.96      0.92      5290\n",
      "          1       0.75      0.48      0.59      1290\n",
      "\n",
      "avg / total       0.86      0.87      0.86      6580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,34):\n",
    "    print(classification_report(y_test.iloc[:,i], y_pred[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2vec + PCA + AdaBoost\n",
    "\n",
    "Here, I am trying to improve the results of the first classification by combining Doc2vec (instead of tf-idf), Principal Component Analysis, and Adaptive Boosting classification algorithm.\n",
    "\n",
    "The code is based on the following articles:\n",
    "\n",
    "https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/ch04.html#idm140629387022352\n",
    "\n",
    "https://stackoverflow.com/questions/50278744/pipeline-and-gridsearch-for-doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizer(BaseEstimator, TransformerMixin):\n",
    "    '''Class normalizes text'''\n",
    "    def __init__(self, language='english'):\n",
    "        self.stopwords  = set(nltk.corpus.stopwords.words(language))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, documents):\n",
    "        \n",
    "        cleaned_documents = []\n",
    "        \n",
    "        for text in documents:\n",
    "            tokens = word_tokenize(text)\n",
    "            tokens = [t for t in tokens if t.lower() not in self.stopwords and t.lower() not in string.punctuation]\n",
    "        \n",
    "            clean_tokens = []\n",
    "        \n",
    "            for tok in tokens:\n",
    "                clean_tok = self.lemmatizer.lemmatize(tok).lower().strip()\n",
    "                clean_tokens.append(clean_tok)\n",
    "                cleaned_doc = ' '.join([str(elem) for elem in clean_tokens]) \n",
    "                \n",
    "            cleaned_documents.append(cleaned_doc)\n",
    "            \n",
    "        return pd.Series(cleaned_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2VecModel(BaseEstimator):\n",
    "    '''Class transforms messages and gives an output as Doc2Vec numerical representation'''\n",
    "    def __init__(self, dm=1, vector_size=300, window=2, learning_rate=0.02):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.d2v_model = None\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.dm = dm\n",
    "\n",
    "    def fit(self, raw_documents, y=None):\n",
    "        # Initialize model\n",
    "        self.d2v_model = Doc2Vec(vector_size=self.vector_size, window=self.window, dm=self.dm, epochs=20, \n",
    "                                 alpha=0.025, min_alpha=0.001, learning_rate = self.learning_rate)\n",
    "        \n",
    "        # Tag docs    \n",
    "        tagged_documents = [\n",
    "            TaggedDocument(words, ['d{}'.format(idx)])\n",
    "            for idx, words in enumerate(raw_documents)\n",
    "        ]\n",
    "        \n",
    "        # Build vocabulary\n",
    "        self.d2v_model.build_vocab(tagged_documents)\n",
    "        \n",
    "        # Train model\n",
    "        self.d2v_model.train(tagged_documents, total_examples=len(tagged_documents), epochs=self.d2v_model.epochs)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        X = []\n",
    "        for index, row in raw_documents.iteritems():\n",
    "            X.append(self.d2v_model.infer_vector(row))\n",
    "        X = pd.DataFrame(X, index=raw_documents.index)\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, raw_documents, y=None):\n",
    "        self.fit(raw_documents)\n",
    "        return self.transform(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_doc2vec = Pipeline([\n",
    "    ('normalizer', TextNormalizer()),\n",
    "    ('doc2vec', Doc2VecModel()),\n",
    "    ('pca', PCA(n_components=100)),\n",
    "    ('clf', MultiOutputClassifier(AdaBoostClassifier(n_estimators = 200, learning_rate = 0.01)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalizer', TextNormalizer(language=None)), ('doc2vec', Doc2VecModel(dm=1, vector_size=300, window=2)), ('pca', PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.01, n_estimators=200, random_state=None),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "pipeline_doc2vec.fit(X_train['message'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_doc2vec.predict(X_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = list(Y.columns)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91      5489\n",
      "          1       0.00      0.00      0.00      1091\n",
      "\n",
      "avg / total       0.70      0.83      0.76      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6552\n",
      "          1       0.00      0.00      0.00        28\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      1.00      0.74      3855\n",
      "          1       0.68      0.01      0.01      2725\n",
      "\n",
      "avg / total       0.63      0.59      0.44      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      6081\n",
      "          1       0.00      0.00      0.00       499\n",
      "\n",
      "avg / total       0.85      0.92      0.89      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6240\n",
      "          1       0.00      0.00      0.00       340\n",
      "\n",
      "avg / total       0.90      0.95      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6384\n",
      "          1       0.00      0.00      0.00       196\n",
      "\n",
      "avg / total       0.94      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6456\n",
      "          1       0.00      0.00      0.00       124\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6358\n",
      "          1       0.00      0.00      0.00       222\n",
      "\n",
      "avg / total       0.93      0.97      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6580\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6154\n",
      "          1       0.00      0.00      0.00       426\n",
      "\n",
      "avg / total       0.87      0.94      0.90      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94      5853\n",
      "          1       0.00      0.00      0.00       727\n",
      "\n",
      "avg / total       0.79      0.89      0.84      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      6048\n",
      "          1       0.00      0.00      0.00       532\n",
      "\n",
      "avg / total       0.84      0.92      0.88      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6483\n",
      "          1       0.00      0.00      0.00        97\n",
      "\n",
      "avg / total       0.97      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6434\n",
      "          1       0.00      0.00      0.00       146\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6488\n",
      "          1       0.00      0.00      0.00        92\n",
      "\n",
      "avg / total       0.97      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6353\n",
      "          1       0.00      0.00      0.00       227\n",
      "\n",
      "avg / total       0.93      0.97      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      6266\n",
      "          1       0.00      0.00      0.00       314\n",
      "\n",
      "avg / total       0.91      0.95      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93      5684\n",
      "          1       0.00      0.00      0.00       896\n",
      "\n",
      "avg / total       0.75      0.86      0.80      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6157\n",
      "          1       0.00      0.00      0.00       423\n",
      "\n",
      "avg / total       0.88      0.94      0.90      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      6266\n",
      "          1       0.00      0.00      0.00       314\n",
      "\n",
      "avg / total       0.91      0.95      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6245\n",
      "          1       0.00      0.00      0.00       335\n",
      "\n",
      "avg / total       0.90      0.95      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6453\n",
      "          1       0.00      0.00      0.00       127\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6544\n",
      "          1       0.00      0.00      0.00        36\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6511\n",
      "          1       0.00      0.00      0.00        69\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6544\n",
      "          1       0.00      0.00      0.00        36\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6507\n",
      "          1       0.00      0.00      0.00        73\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6298\n",
      "          1       0.00      0.00      0.00       282\n",
      "\n",
      "avg / total       0.92      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      1.00      0.83      4708\n",
      "          1       0.50      0.00      0.00      1872\n",
      "\n",
      "avg / total       0.65      0.72      0.60      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      6026\n",
      "          1       0.00      0.00      0.00       554\n",
      "\n",
      "avg / total       0.84      0.92      0.88      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95      5955\n",
      "          1       0.00      0.00      0.00       625\n",
      "\n",
      "avg / total       0.82      0.91      0.86      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6513\n",
      "          1       0.00      0.00      0.00        67\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95      5936\n",
      "          1       0.00      0.00      0.00       644\n",
      "\n",
      "avg / total       0.81      0.90      0.86      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6447\n",
      "          1       0.00      0.00      0.00       133\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6224\n",
      "          1       0.00      0.00      0.00       356\n",
      "\n",
      "avg / total       0.89      0.95      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90      5338\n",
      "          1       0.00      0.00      0.00      1242\n",
      "\n",
      "avg / total       0.66      0.81      0.73      6580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in category_names:\n",
    "    print(classification_report(y_test[i], y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Doc2Vec model did not give a better result than the first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding text statistics as features\n",
    "\n",
    "The next endeavour to improve the results assumed adding new features to the model based on the characteristics of the messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([X_train['message'], y_train], axis=1)\n",
    "df = pd.melt(new_df,id_vars=['message'],var_name='category', value_name='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_length'] = df['message'].apply(len)\n",
    "df['capitals'] = df['message'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "df['num_exclamation_marks'] =df['message'].apply(lambda x: x.count('!'))\n",
    "df['num_question_marks'] = df['message'].apply(lambda x: x.count('?'))\n",
    "df['num_punctuation'] = df['message'].apply(lambda x: sum(x.count(w) for w in list(string.punctuation)))\n",
    "df['num_unique_words'] = df['message'].apply(lambda x: len(set(w for w in x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>category</th>\n",
       "      <th>values</th>\n",
       "      <th>total_length</th>\n",
       "      <th>capitals</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>num_punctuation</th>\n",
       "      <th>num_unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are some people that I know in central P...</td>\n",
       "      <td>request</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Myanmar [Burma] Climate Change Watch websi...</td>\n",
       "      <td>request</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A ferry service operates to Pulau Nias Island.</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>About a 100 feet to its left, a tower is cleav...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An expected increase in global commodity and o...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACF's field teams will provide access to clean...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other sources put the epicenter in the sparsel...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Canadians had until yesterday to see their ind...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what will happen to the students that died at ...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The person would like to know where or which h...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Because of the widespread public support it re...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>http://twitvid.com/8B55C - Driving down the hi...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>One way!Try to tell no to something wrong.</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I have never been able to participate because ...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Turkmenistan's harsh crackdown on opposition f...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Many people have moved into newly-constructed ...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>In the coastal Zugdidi district, the floods we...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Haiti hit by 7.0 magnitude earthquake building...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Besides rains, water discharge by upstream dam...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>On the left side of the canal, the motorway wa...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>On behalf of ACT members in Bangladesh Christi...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>417</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Current per capita income from food and cash c...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UNHCR reported this week that two new refugee ...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I need food and water for martissant people ex...</td>\n",
       "      <td>request</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>This funding will: - Fill critical gaps in the...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Traditionally, the nomadic population live on ...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Village in Delmas 103 that has yet to find any...</td>\n",
       "      <td>request</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>They claimed that the voter registration proce...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>They raised funds, visited victims, distribute...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Please note that the main problem is the phone...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671096</th>\n",
       "      <td>An attacker rode a motorcycle up to an army ch...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671097</th>\n",
       "      <td>Military and volunteer groups carried out init...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671098</th>\n",
       "      <td>Lost power in Short Hills, NJ as of 3pm Monday...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671099</th>\n",
       "      <td>It will support the Integrated Economic Platfo...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671100</th>\n",
       "      <td>Us, the tradeswoman of dessalines, rue perodin...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671101</th>\n",
       "      <td>I am a poor man i have youngr children But the...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671102</th>\n",
       "      <td>Frightening footage of the recent disaster cap...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671103</th>\n",
       "      <td>Saouti Hadara, the editor of the privately-ow...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671104</th>\n",
       "      <td>I can't find my family, they're 4 call me to t...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671105</th>\n",
       "      <td>M.javid Bannu road near pusha pul Rehman road ...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671106</th>\n",
       "      <td>Aircraft full of blankets, tents, emergency re...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671107</th>\n",
       "      <td>My friends hello please dont forget us we cann...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671108</th>\n",
       "      <td>Can you send a tent to my address?</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671109</th>\n",
       "      <td>Pray for me in the hurricane :(</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671110</th>\n",
       "      <td>These adverse climatic conditions have been at...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671111</th>\n",
       "      <td>It is that later there will be a 6. 8 aftersho...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671112</th>\n",
       "      <td>The overall foodgrain production in these Stat...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671113</th>\n",
       "      <td>We are at the top of Fontamara 43 (area of Car...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671114</th>\n",
       "      <td>we can not get access to the pass or card beca...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671115</th>\n",
       "      <td>A spokesperson from Muslim Aid said, \"Sustaine...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671116</th>\n",
       "      <td>Recent snow flurries and fog have prevented th...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671117</th>\n",
       "      <td>He was reported by The Jakarta Post on 7 March...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671118</th>\n",
       "      <td>Since southern Orissa could be severely affect...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671119</th>\n",
       "      <td>Some carried away corpses on makeshift stretch...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671120</th>\n",
       "      <td>He went with success but he just comes back wi...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671121</th>\n",
       "      <td>It is positive that ECHO has increased its all...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671122</th>\n",
       "      <td>(h) Augmentation of telecom facilities -- depu...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671123</th>\n",
       "      <td>In the neighbouring storm-hit state of Bihar, ...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671124</th>\n",
       "      <td>mwen besoin dlo avek mange na zon bon repos, l...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671125</th>\n",
       "      <td>Evacuations (serious patients) - 484, rescued ...</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671126 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  message       category  \\\n",
       "0       There are some people that I know in central P...        request   \n",
       "1       The Myanmar [Burma] Climate Change Watch websi...        request   \n",
       "2          A ferry service operates to Pulau Nias Island.        request   \n",
       "3       About a 100 feet to its left, a tower is cleav...        request   \n",
       "4       An expected increase in global commodity and o...        request   \n",
       "5       ACF's field teams will provide access to clean...        request   \n",
       "6       Other sources put the epicenter in the sparsel...        request   \n",
       "7       Canadians had until yesterday to see their ind...        request   \n",
       "8       what will happen to the students that died at ...        request   \n",
       "9       The person would like to know where or which h...        request   \n",
       "10      Because of the widespread public support it re...        request   \n",
       "11      http://twitvid.com/8B55C - Driving down the hi...        request   \n",
       "12            One way!Try to tell no to something wrong.         request   \n",
       "13      I have never been able to participate because ...        request   \n",
       "14      Turkmenistan's harsh crackdown on opposition f...        request   \n",
       "15      Many people have moved into newly-constructed ...        request   \n",
       "16      In the coastal Zugdidi district, the floods we...        request   \n",
       "17      Haiti hit by 7.0 magnitude earthquake building...        request   \n",
       "18      Besides rains, water discharge by upstream dam...        request   \n",
       "19      On the left side of the canal, the motorway wa...        request   \n",
       "20      On behalf of ACT members in Bangladesh Christi...        request   \n",
       "21      Current per capita income from food and cash c...        request   \n",
       "22      UNHCR reported this week that two new refugee ...        request   \n",
       "23      I need food and water for martissant people ex...        request   \n",
       "24      This funding will: - Fill critical gaps in the...        request   \n",
       "25      Traditionally, the nomadic population live on ...        request   \n",
       "26      Village in Delmas 103 that has yet to find any...        request   \n",
       "27      They claimed that the voter registration proce...        request   \n",
       "28      They raised funds, visited victims, distribute...        request   \n",
       "29      Please note that the main problem is the phone...        request   \n",
       "...                                                   ...            ...   \n",
       "671096  An attacker rode a motorcycle up to an army ch...  direct_report   \n",
       "671097  Military and volunteer groups carried out init...  direct_report   \n",
       "671098  Lost power in Short Hills, NJ as of 3pm Monday...  direct_report   \n",
       "671099  It will support the Integrated Economic Platfo...  direct_report   \n",
       "671100  Us, the tradeswoman of dessalines, rue perodin...  direct_report   \n",
       "671101  I am a poor man i have youngr children But the...  direct_report   \n",
       "671102  Frightening footage of the recent disaster cap...  direct_report   \n",
       "671103  Saouti Hadara, the editor of the privately-ow...  direct_report   \n",
       "671104  I can't find my family, they're 4 call me to t...  direct_report   \n",
       "671105  M.javid Bannu road near pusha pul Rehman road ...  direct_report   \n",
       "671106  Aircraft full of blankets, tents, emergency re...  direct_report   \n",
       "671107  My friends hello please dont forget us we cann...  direct_report   \n",
       "671108                Can you send a tent to my address?   direct_report   \n",
       "671109                    Pray for me in the hurricane :(  direct_report   \n",
       "671110  These adverse climatic conditions have been at...  direct_report   \n",
       "671111  It is that later there will be a 6. 8 aftersho...  direct_report   \n",
       "671112  The overall foodgrain production in these Stat...  direct_report   \n",
       "671113  We are at the top of Fontamara 43 (area of Car...  direct_report   \n",
       "671114  we can not get access to the pass or card beca...  direct_report   \n",
       "671115  A spokesperson from Muslim Aid said, \"Sustaine...  direct_report   \n",
       "671116  Recent snow flurries and fog have prevented th...  direct_report   \n",
       "671117  He was reported by The Jakarta Post on 7 March...  direct_report   \n",
       "671118  Since southern Orissa could be severely affect...  direct_report   \n",
       "671119  Some carried away corpses on makeshift stretch...  direct_report   \n",
       "671120  He went with success but he just comes back wi...  direct_report   \n",
       "671121  It is positive that ECHO has increased its all...  direct_report   \n",
       "671122  (h) Augmentation of telecom facilities -- depu...  direct_report   \n",
       "671123  In the neighbouring storm-hit state of Bihar, ...  direct_report   \n",
       "671124  mwen besoin dlo avek mange na zon bon repos, l...  direct_report   \n",
       "671125  Evacuations (serious patients) - 484, rescued ...  direct_report   \n",
       "\n",
       "        values  total_length  capitals  num_exclamation_marks  \\\n",
       "0            1           115         4                      0   \n",
       "1            1           159         6                      0   \n",
       "2            0            46         4                      0   \n",
       "3            0           115         1                      0   \n",
       "4            0           191         1                      0   \n",
       "5            0           166         3                      0   \n",
       "6            0           147         4                      0   \n",
       "7            0           213         2                      0   \n",
       "8            0            61         1                      0   \n",
       "9            0           123         2                      0   \n",
       "10           0           187        28                      0   \n",
       "11           0            93         4                      0   \n",
       "12           0            43         2                      1   \n",
       "13           0           127         3                      0   \n",
       "14           0           196         4                      0   \n",
       "15           0            99         1                      0   \n",
       "16           0           130         3                      0   \n",
       "17           0           129         6                      0   \n",
       "18           0           130         5                      0   \n",
       "19           0           152         5                      0   \n",
       "20           0           417        28                      0   \n",
       "21           0           165         1                      0   \n",
       "22           0           105        13                      0   \n",
       "23           1           105         2                      0   \n",
       "24           0           450         5                      0   \n",
       "25           0           127         1                      0   \n",
       "26           1            99         3                      0   \n",
       "27           0           264         7                      0   \n",
       "28           0            90         1                      0   \n",
       "29           0           120         4                      0   \n",
       "...        ...           ...       ...                    ...   \n",
       "671096       0           165         2                      0   \n",
       "671097       0           153         1                      0   \n",
       "671098       0            53         7                      0   \n",
       "671099       1           217         5                      0   \n",
       "671100       0           110         3                      1   \n",
       "671101       0           151         6                      0   \n",
       "671102       0           187         1                      0   \n",
       "671103       0           202         9                      0   \n",
       "671104       1            84         1                      0   \n",
       "671105       1           158         6                      0   \n",
       "671106       0           345         7                      0   \n",
       "671107       1           127         2                      0   \n",
       "671108       1            35         1                      0   \n",
       "671109       1            31         1                      0   \n",
       "671110       1            81         3                      0   \n",
       "671111       1            72         2                      0   \n",
       "671112       0           102         2                      0   \n",
       "671113       1           177         4                      0   \n",
       "671114       1           170         0                      0   \n",
       "671115       1           247         4                      0   \n",
       "671116       0           187         1                      0   \n",
       "671117       0           184         6                      0   \n",
       "671118       0           204         6                      0   \n",
       "671119       1           186         1                      0   \n",
       "671120       0            59         1                      0   \n",
       "671121       0           202         5                      0   \n",
       "671122       0           100         6                      0   \n",
       "671123       0           177         2                      0   \n",
       "671124       0            54         0                      0   \n",
       "671125       0            81         1                      0   \n",
       "\n",
       "        num_question_marks  num_punctuation  num_unique_words  \n",
       "0                        0                4                21  \n",
       "1                        0                3                24  \n",
       "2                        0                1                 8  \n",
       "3                        0                3                23  \n",
       "4                        0                2                25  \n",
       "5                        0                5                20  \n",
       "6                        0                2                21  \n",
       "7                        0                2                30  \n",
       "8                        1                1                10  \n",
       "9                        0                1                22  \n",
       "10                       0                6                26  \n",
       "11                       0                6                13  \n",
       "12                       0                2                 7  \n",
       "13                       0                5                23  \n",
       "14                       0                2                25  \n",
       "15                       0                4                13  \n",
       "16                       0                2                19  \n",
       "17                       0                3                20  \n",
       "18                       0                2                19  \n",
       "19                       0                2                24  \n",
       "20                       0               10                52  \n",
       "21                       0                7                20  \n",
       "22                       0                3                17  \n",
       "23                       0                2                15  \n",
       "24                       0               12                51  \n",
       "25                       0                3                20  \n",
       "26                       0                4                18  \n",
       "27                       0                3                35  \n",
       "28                       0                3                12  \n",
       "29                       0                1                19  \n",
       "...                    ...              ...               ...  \n",
       "671096                   0                5                25  \n",
       "671097                   0                2                22  \n",
       "671098                   0                2                11  \n",
       "671099                   0                5                31  \n",
       "671100                   0                6                19  \n",
       "671101                   0                4                26  \n",
       "671102                   0                4                25  \n",
       "671103                   0                5                29  \n",
       "671104                   0                4                17  \n",
       "671105                   0                4                27  \n",
       "671106                   0                5                42  \n",
       "671107                   0                2                22  \n",
       "671108                   1                1                 8  \n",
       "671109                   0                2                 7  \n",
       "671110                   0                1                12  \n",
       "671111                   0                3                15  \n",
       "671112                   0                2                17  \n",
       "671113                   0               11                24  \n",
       "671114                   0                3                29  \n",
       "671115                   0                6                34  \n",
       "671116                   0                2                27  \n",
       "671117                   0                1                30  \n",
       "671118                   0                2                30  \n",
       "671119                   0                1                26  \n",
       "671120                   0                0                11  \n",
       "671121                   0                2                30  \n",
       "671122                   0                5                14  \n",
       "671123                   0                6                26  \n",
       "671124                   0                1                10  \n",
       "671125                   0                7                11  \n",
       "\n",
       "[671126 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capitals</th>\n",
       "      <th>total_length</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>num_punctuation</th>\n",
       "      <th>num_unique_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>9.534247</td>\n",
       "      <td>319.264840</td>\n",
       "      <td>0.022831</td>\n",
       "      <td>0.059361</td>\n",
       "      <td>7.515982</td>\n",
       "      <td>39.844749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>6.648870</td>\n",
       "      <td>172.372266</td>\n",
       "      <td>0.046671</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>4.652169</td>\n",
       "      <td>24.824191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>7.804114</td>\n",
       "      <td>244.441724</td>\n",
       "      <td>0.059745</td>\n",
       "      <td>0.060725</td>\n",
       "      <td>6.352595</td>\n",
       "      <td>32.652302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>6.803922</td>\n",
       "      <td>238.941176</td>\n",
       "      <td>0.091503</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>7.689542</td>\n",
       "      <td>31.813725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>6.907317</td>\n",
       "      <td>256.056098</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.034146</td>\n",
       "      <td>6.002439</td>\n",
       "      <td>33.634146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>8.539911</td>\n",
       "      <td>264.465632</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.031042</td>\n",
       "      <td>6.588692</td>\n",
       "      <td>35.145233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>7.047310</td>\n",
       "      <td>124.914999</td>\n",
       "      <td>0.105277</td>\n",
       "      <td>0.118014</td>\n",
       "      <td>4.332987</td>\n",
       "      <td>20.116194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>7.000535</td>\n",
       "      <td>169.232210</td>\n",
       "      <td>0.066881</td>\n",
       "      <td>0.138042</td>\n",
       "      <td>4.441948</td>\n",
       "      <td>23.582129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>9.319613</td>\n",
       "      <td>283.762712</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>8.058111</td>\n",
       "      <td>35.719128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>8.027149</td>\n",
       "      <td>294.045249</td>\n",
       "      <td>0.063348</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>7.076923</td>\n",
       "      <td>36.864253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>7.944271</td>\n",
       "      <td>260.420163</td>\n",
       "      <td>0.032561</td>\n",
       "      <td>0.029430</td>\n",
       "      <td>6.231684</td>\n",
       "      <td>34.264872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>7.364211</td>\n",
       "      <td>190.010393</td>\n",
       "      <td>0.056033</td>\n",
       "      <td>0.074559</td>\n",
       "      <td>5.680524</td>\n",
       "      <td>26.803886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>7.145631</td>\n",
       "      <td>233.635922</td>\n",
       "      <td>0.067961</td>\n",
       "      <td>0.053398</td>\n",
       "      <td>5.873786</td>\n",
       "      <td>30.427184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>7.531371</td>\n",
       "      <td>239.391170</td>\n",
       "      <td>0.046476</td>\n",
       "      <td>0.037955</td>\n",
       "      <td>5.945778</td>\n",
       "      <td>31.735089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>7.775974</td>\n",
       "      <td>241.063636</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.053247</td>\n",
       "      <td>6.007143</td>\n",
       "      <td>31.733766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>8.106212</td>\n",
       "      <td>256.005010</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>7.149299</td>\n",
       "      <td>32.976954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>7.539755</td>\n",
       "      <td>252.828746</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>5.487768</td>\n",
       "      <td>33.646789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>9.072072</td>\n",
       "      <td>223.617117</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.058559</td>\n",
       "      <td>5.801802</td>\n",
       "      <td>30.355856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>9.417943</td>\n",
       "      <td>217.433260</td>\n",
       "      <td>0.041575</td>\n",
       "      <td>0.063457</td>\n",
       "      <td>5.969365</td>\n",
       "      <td>29.746171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>4.898876</td>\n",
       "      <td>157.438202</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>4.741573</td>\n",
       "      <td>22.921348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>7.200856</td>\n",
       "      <td>169.676139</td>\n",
       "      <td>0.066174</td>\n",
       "      <td>0.098482</td>\n",
       "      <td>4.625924</td>\n",
       "      <td>24.497859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>7.423251</td>\n",
       "      <td>240.396163</td>\n",
       "      <td>0.047404</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>5.937923</td>\n",
       "      <td>31.945824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>6.880342</td>\n",
       "      <td>227.280152</td>\n",
       "      <td>0.046534</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>5.838557</td>\n",
       "      <td>30.422602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>8.478916</td>\n",
       "      <td>276.587349</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>6.590361</td>\n",
       "      <td>35.617470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>7.481935</td>\n",
       "      <td>123.578979</td>\n",
       "      <td>0.062108</td>\n",
       "      <td>0.126605</td>\n",
       "      <td>3.962078</td>\n",
       "      <td>19.852195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>7.542342</td>\n",
       "      <td>218.542342</td>\n",
       "      <td>0.048649</td>\n",
       "      <td>0.048649</td>\n",
       "      <td>5.717117</td>\n",
       "      <td>29.724324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>7.633423</td>\n",
       "      <td>200.814016</td>\n",
       "      <td>0.070081</td>\n",
       "      <td>0.064690</td>\n",
       "      <td>5.029650</td>\n",
       "      <td>27.482480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>7.717329</td>\n",
       "      <td>216.188256</td>\n",
       "      <td>0.045481</td>\n",
       "      <td>0.061025</td>\n",
       "      <td>6.018423</td>\n",
       "      <td>29.647668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>11.544444</td>\n",
       "      <td>379.288889</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>10.011111</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>8.695558</td>\n",
       "      <td>222.257313</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0.075298</td>\n",
       "      <td>7.090466</td>\n",
       "      <td>30.242687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>7.965517</td>\n",
       "      <td>239.594828</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>6.612069</td>\n",
       "      <td>31.525862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>7.216304</td>\n",
       "      <td>247.002174</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.039130</td>\n",
       "      <td>6.167391</td>\n",
       "      <td>32.493478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>7.805310</td>\n",
       "      <td>237.617860</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.041834</td>\n",
       "      <td>6.706356</td>\n",
       "      <td>31.347546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>6.772521</td>\n",
       "      <td>182.966467</td>\n",
       "      <td>0.087729</td>\n",
       "      <td>0.081566</td>\n",
       "      <td>5.130506</td>\n",
       "      <td>25.717600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         capitals  total_length  num_exclamation_marks  \\\n",
       "category                                                                 \n",
       "aid_centers              9.534247    319.264840               0.022831   \n",
       "aid_related              6.648870    172.372266               0.046671   \n",
       "buildings                7.804114    244.441724               0.059745   \n",
       "clothing                 6.803922    238.941176               0.091503   \n",
       "cold                     6.907317    256.056098               0.085366   \n",
       "death                    8.539911    264.465632               0.019956   \n",
       "direct_report            7.047310    124.914999               0.105277   \n",
       "earthquake               7.000535    169.232210               0.066881   \n",
       "electricity              9.319613    283.762712               0.147700   \n",
       "fire                     8.027149    294.045249               0.063348   \n",
       "floods                   7.944271    260.420163               0.032561   \n",
       "food                     7.364211    190.010393               0.056033   \n",
       "hospitals                7.145631    233.635922               0.067961   \n",
       "infrastructure_related   7.531371    239.391170               0.046476   \n",
       "medical_help             7.775974    241.063636               0.032468   \n",
       "medical_products         8.106212    256.005010               0.024048   \n",
       "military                 7.539755    252.828746               0.013761   \n",
       "missing_people           9.072072    223.617117               0.054054   \n",
       "money                    9.417943    217.433260               0.041575   \n",
       "offer                    4.898876    157.438202               0.022472   \n",
       "other_aid                7.200856    169.676139               0.066174   \n",
       "other_infrastructure     7.423251    240.396163               0.047404   \n",
       "other_weather            6.880342    227.280152               0.046534   \n",
       "refugees                 8.478916    276.587349               0.027108   \n",
       "request                  7.481935    123.578979               0.062108   \n",
       "search_and_rescue        7.542342    218.542342               0.048649   \n",
       "security                 7.633423    200.814016               0.070081   \n",
       "shelter                  7.717329    216.188256               0.045481   \n",
       "shops                   11.544444    379.288889               0.044444   \n",
       "storm                    8.695558    222.257313               0.169014   \n",
       "tools                    7.965517    239.594828               0.034483   \n",
       "transport                7.216304    247.002174               0.054348   \n",
       "water                    7.805310    237.617860               0.057924   \n",
       "weather_related          6.772521    182.966467               0.087729   \n",
       "\n",
       "                        num_question_marks  num_punctuation  num_unique_words  \n",
       "category                                                                       \n",
       "aid_centers                       0.059361         7.515982         39.844749  \n",
       "aid_related                       0.070617         4.652169         24.824191  \n",
       "buildings                         0.060725         6.352595         32.652302  \n",
       "clothing                          0.071895         7.689542         31.813725  \n",
       "cold                              0.034146         6.002439         33.634146  \n",
       "death                             0.031042         6.588692         35.145233  \n",
       "direct_report                     0.118014         4.332987         20.116194  \n",
       "earthquake                        0.138042         4.441948         23.582129  \n",
       "electricity                       0.062954         8.058111         35.719128  \n",
       "fire                              0.036199         7.076923         36.864253  \n",
       "floods                            0.029430         6.231684         34.264872  \n",
       "food                              0.074559         5.680524         26.803886  \n",
       "hospitals                         0.053398         5.873786         30.427184  \n",
       "infrastructure_related            0.037955         5.945778         31.735089  \n",
       "medical_help                      0.053247         6.007143         31.733766  \n",
       "medical_products                  0.041082         7.149299         32.976954  \n",
       "military                          0.018349         5.487768         33.646789  \n",
       "missing_people                    0.058559         5.801802         30.355856  \n",
       "money                             0.063457         5.969365         29.746171  \n",
       "offer                             0.056180         4.741573         22.921348  \n",
       "other_aid                         0.098482         4.625924         24.497859  \n",
       "other_infrastructure              0.030474         5.937923         31.945824  \n",
       "other_weather                     0.037037         5.838557         30.422602  \n",
       "refugees                          0.042169         6.590361         35.617470  \n",
       "request                           0.126605         3.962078         19.852195  \n",
       "search_and_rescue                 0.048649         5.717117         29.724324  \n",
       "security                          0.064690         5.029650         27.482480  \n",
       "shelter                           0.061025         6.018423         29.647668  \n",
       "shops                             0.022222        10.011111         45.555556  \n",
       "storm                             0.075298         7.090466         30.242687  \n",
       "tools                             0.068966         6.612069         31.525862  \n",
       "transport                         0.039130         6.167391         32.493478  \n",
       "water                             0.041834         6.706356         31.347546  \n",
       "weather_related                   0.081566         5.130506         25.717600  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['values'] == 1].groupby('category').agg(\n",
    "    {\n",
    "         'capitals':'mean',\n",
    "         'total_length':'mean',\n",
    "         'num_exclamation_marks': 'mean',\n",
    "         'num_question_marks': 'mean',\n",
    "         'num_punctuation': 'mean',\n",
    "         'num_unique_words': 'mean'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_stats(BaseEstimator, TransformerMixin):    \n",
    "    '''class returns texts statistics as a dataframe'''\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        length = X.apply(len)\n",
    "        capitals = X.apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "        exclam_marks =X.apply(lambda x: x.count('!'))\n",
    "        question_marks = X.apply(lambda x: x.count('?'))\n",
    "        punctuation = X.apply(lambda x: sum(x.count(w) for w in list(string.punctuation)))\n",
    "        unique_words = X.apply(lambda x: len(set(w for w in x.split())))\n",
    "        \n",
    "        df = pd.concat([length, capitals, exclam_marks, question_marks, punctuation, unique_words], axis=1)\n",
    "        df.columns = ['length', 'capitals', 'exclam_marks', 'question_marks', 'punctuation',\n",
    "                                      'unique_words']\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I made two pipelines: the first one with Adaptive Boosting algorithm as a classifier, and the second one with Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ada_ts = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        \n",
    "        ('nlp_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        \n",
    "        ('text_stats', text_stats())\n",
    "    ])),\n",
    "    \n",
    "    ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('nlp_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df...mator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_ada_ts.fit(X_train['message'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__estimator__n_estimators': [100, 200, 300],\n",
    "              'clf__estimator__learning_rate': [0.01, 0.1, 0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_ts_model = GridSearchCV(pipeline_ada_ts, param_grid=parameters, verbose = 5, n_jobs = -1, cv=2, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV] clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=100, score=0.7360597147628853, total= 3.8min\n",
      "[CV] clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  4.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=100, score=0.7264374500299777, total= 3.8min\n",
      "[CV] clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  9.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=200, score=0.77044188480111, total= 6.0min\n",
      "[CV] clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed: 16.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=200, score=0.77058472340617, total= 5.9min\n",
      "[CV] clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed: 23.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=300, score=0.7872590202054034, total= 8.0min\n",
      "[CV] clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__learning_rate=0.01, clf__estimator__n_estimators=300, score=0.784405341299615, total= 8.2min\n",
      "[CV] clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=100, score=0.8109587607356085, total= 3.9min\n",
      "[CV] clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=100, score=0.7997035700479141, total= 3.9min\n",
      "[CV] clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=200, score=0.8113351809565801, total= 5.9min\n",
      "[CV] clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=200, score=0.8040942932880606, total= 5.9min\n",
      "[CV] clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=300, score=0.8109609821034566, total= 8.0min\n",
      "[CV] clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__learning_rate=0.1, clf__estimator__n_estimators=300, score=0.7996688567734983, total= 8.0min\n",
      "[CV] clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=100, score=0.8092947101492798, total= 3.9min\n",
      "[CV] clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=100, score=0.7988254677682005, total= 3.9min\n",
      "[CV] clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=200, score=0.8014591008088158, total= 6.0min\n",
      "[CV] clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=200, score=0.7878049942054457, total= 6.0min\n",
      "[CV] clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=300, score=0.7955427252433521, total= 8.1min\n",
      "[CV] clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__learning_rate=0.2, clf__estimator__n_estimators=300, score=0.7836552989727359, total= 8.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed: 127.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('nlp_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df...mator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__estimator__n_estimators': [100, 200, 300], 'clf__estimator__learning_rate': [0.01, 0.1, 0.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_ts_model.fit(X_train['message'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.807715 using {'clf__estimator__learning_rate': 0.1, 'clf__estimator__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (ada_ts_model.best_score_, ada_ts_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ada_ts_model.predict(X_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = list(Y.columns)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.94      5475\n",
      "          1       0.82      0.42      0.56      1105\n",
      "\n",
      "avg / total       0.88      0.89      0.87      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6535\n",
      "          1       0.00      0.00      0.00        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.87      0.79      3851\n",
      "          1       0.75      0.53      0.62      2729\n",
      "\n",
      "avg / total       0.73      0.73      0.72      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96      6055\n",
      "          1       0.69      0.12      0.21       525\n",
      "\n",
      "avg / total       0.91      0.93      0.90      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      6217\n",
      "          1       0.79      0.17      0.28       363\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      6385\n",
      "          1       0.67      0.10      0.18       195\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6468\n",
      "          1       0.00      0.00      0.00       112\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      6378\n",
      "          1       0.71      0.17      0.27       202\n",
      "\n",
      "avg / total       0.97      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      6154\n",
      "          1       0.76      0.60      0.67       426\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      5838\n",
      "          1       0.79      0.75      0.77       742\n",
      "\n",
      "avg / total       0.95      0.95      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      5982\n",
      "          1       0.84      0.48      0.61       598\n",
      "\n",
      "avg / total       0.94      0.94      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6478\n",
      "          1       0.78      0.30      0.44       102\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6433\n",
      "          1       0.65      0.15      0.24       147\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6500\n",
      "          1       0.71      0.12      0.21        80\n",
      "\n",
      "avg / total       0.99      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6363\n",
      "          1       0.70      0.15      0.25       217\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6273\n",
      "          1       0.80      0.29      0.43       307\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93      5741\n",
      "          1       0.48      0.03      0.06       839\n",
      "\n",
      "avg / total       0.83      0.87      0.82      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6157\n",
      "          1       0.60      0.02      0.04       423\n",
      "\n",
      "avg / total       0.92      0.94      0.91      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6276\n",
      "          1       0.82      0.13      0.23       304\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6207\n",
      "          1       0.81      0.24      0.37       373\n",
      "\n",
      "avg / total       0.95      0.95      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6441\n",
      "          1       0.57      0.12      0.20       139\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6542\n",
      "          1       0.00      0.00      0.00        38\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6512\n",
      "          1       0.57      0.06      0.11        68\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6545\n",
      "          1       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6493\n",
      "          1       0.40      0.02      0.04        87\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6304\n",
      "          1       0.67      0.01      0.03       276\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91      4757\n",
      "          1       0.90      0.54      0.68      1823\n",
      "\n",
      "avg / total       0.86      0.86      0.84      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6034\n",
      "          1       0.91      0.49      0.64       546\n",
      "\n",
      "avg / total       0.95      0.95      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      5970\n",
      "          1       0.82      0.37      0.51       610\n",
      "\n",
      "avg / total       0.93      0.93      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6514\n",
      "          1       0.50      0.06      0.11        66\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      5981\n",
      "          1       0.89      0.75      0.81       599\n",
      "\n",
      "avg / total       0.97      0.97      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6420\n",
      "          1       0.81      0.18      0.30       160\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6225\n",
      "          1       0.63      0.03      0.06       355\n",
      "\n",
      "avg / total       0.93      0.95      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91      5305\n",
      "          1       0.80      0.30      0.43      1275\n",
      "\n",
      "avg / total       0.84      0.85      0.82      6580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in category_names:\n",
    "    print(classification_report(y_test[i], y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf_ts = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        \n",
    "        ('nlp_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        \n",
    "        ('text_stats', text_stats())\n",
    "    ])),\n",
    "    \n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('nlp_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_rf_ts.fit(X_train['message'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__estimator__n_estimators': [200, 300],\n",
    "    'clf__estimator__min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "rf_ts_model = GridSearchCV(pipeline_rf_ts, param_grid=parameters, verbose = 5, n_jobs = -1, cv=2, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200, score=0.816842697260615, total= 8.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 10.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200, score=0.8173378095610646, total= 8.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed: 20.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300, score=0.8176832997957235, total=12.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed: 34.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300, score=0.8199705285890831, total=12.5min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed: 49.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200, score=0.81973904188176, total= 8.1min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200, score=0.8183907371417456, total= 8.2min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=300, score=0.8192431266219343, total=11.4min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=300, score=0.8219819959205732, total=11.5min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=200, score=0.8177213166701901, total= 7.7min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=200, score=0.8196843185692426, total= 7.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=300, score=0.8202850867994, total=10.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=300, score=0.8229806353224385, total=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 138.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('nlp_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__estimator__n_estimators': [200, 300], 'clf__estimator__min_samples_split': [2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_ts_model.fit(X_train['message'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.821633 using {'clf__estimator__min_samples_split': 4, 'clf__estimator__n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (rf_ts_model.best_score_, rf_ts_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_ts_model.predict(X_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = list(Y.columns)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.columns = category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94      5448\n",
      "          1       0.88      0.48      0.62      1132\n",
      "\n",
      "avg / total       0.90      0.90      0.89      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6546\n",
      "          1       0.00      0.00      0.00        34\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.85      0.82      3896\n",
      "          1       0.76      0.70      0.73      2684\n",
      "\n",
      "avg / total       0.79      0.79      0.79      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      6047\n",
      "          1       0.65      0.06      0.11       533\n",
      "\n",
      "avg / total       0.90      0.92      0.89      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6227\n",
      "          1       1.00      0.07      0.12       353\n",
      "\n",
      "avg / total       0.95      0.95      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      6408\n",
      "          1       0.57      0.02      0.04       172\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6465\n",
      "          1       0.00      0.00      0.00       115\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6349\n",
      "          1       0.68      0.06      0.10       231\n",
      "\n",
      "avg / total       0.96      0.97      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6175\n",
      "          1       0.86      0.35      0.50       405\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      5863\n",
      "          1       0.84      0.59      0.70       717\n",
      "\n",
      "avg / total       0.94      0.94      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      6043\n",
      "          1       0.85      0.36      0.51       537\n",
      "\n",
      "avg / total       0.94      0.94      0.93      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6474\n",
      "          1       0.43      0.03      0.05       106\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6430\n",
      "          1       1.00      0.03      0.05       150\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6507\n",
      "          1       1.00      0.03      0.05        73\n",
      "\n",
      "avg / total       0.99      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      6392\n",
      "          1       0.33      0.02      0.03       188\n",
      "\n",
      "avg / total       0.95      0.97      0.96      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6282\n",
      "          1       0.92      0.15      0.26       298\n",
      "\n",
      "avg / total       0.96      0.96      0.95      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93      5755\n",
      "          1       0.69      0.02      0.04       825\n",
      "\n",
      "avg / total       0.85      0.88      0.82      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6170\n",
      "          1       0.50      0.00      0.00       410\n",
      "\n",
      "avg / total       0.91      0.94      0.91      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6263\n",
      "          1       0.78      0.09      0.16       317\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6251\n",
      "          1       0.79      0.11      0.20       329\n",
      "\n",
      "avg / total       0.95      0.95      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6446\n",
      "          1       0.71      0.04      0.07       134\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6544\n",
      "          1       0.00      0.00      0.00        36\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6519\n",
      "          1       0.00      0.00      0.00        61\n",
      "\n",
      "avg / total       0.98      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6539\n",
      "          1       0.00      0.00      0.00        41\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6510\n",
      "          1       0.00      0.00      0.00        70\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6305\n",
      "          1       0.00      0.00      0.00       275\n",
      "\n",
      "avg / total       0.92      0.96      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92      4769\n",
      "          1       0.85      0.68      0.76      1811\n",
      "\n",
      "avg / total       0.88      0.88      0.87      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6031\n",
      "          1       0.91      0.42      0.58       549\n",
      "\n",
      "avg / total       0.95      0.95      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      5979\n",
      "          1       0.79      0.50      0.61       601\n",
      "\n",
      "avg / total       0.94      0.94      0.94      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6513\n",
      "          1       0.50      0.01      0.03        67\n",
      "\n",
      "avg / total       0.98      0.99      0.99      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      6001\n",
      "          1       0.89      0.76      0.82       579\n",
      "\n",
      "avg / total       0.97      0.97      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6449\n",
      "          1       0.80      0.09      0.16       131\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6222\n",
      "          1       0.43      0.01      0.02       358\n",
      "\n",
      "avg / total       0.92      0.95      0.92      6580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92      5271\n",
      "          1       0.83      0.36      0.50      1309\n",
      "\n",
      "avg / total       0.86      0.86      0.83      6580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in category_names:\n",
    "    print(classification_report(y_test[i], y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest classifier gave the best result and was chosen as a final model for the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"rf_ts_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(rf_ts_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
